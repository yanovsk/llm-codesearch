{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import openai\n",
    "\n",
    "def get_tokens(string):\n",
    "  encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "  num_tokens = len(encoding.encode(string))\n",
    "  return num_tokens\n",
    "\n",
    "openai.api_key = \"\"\n",
    "\n",
    "def trim_input(user_input):\n",
    "    if get_tokens(user_input) > 14000:\n",
    "        user_input = user_input[:20000]\n",
    "    return user_input\n",
    "\n",
    "def clean_text(text):\n",
    "  \"\"\"\n",
    "  Clean the text by removing certain formatting symbols.\n",
    "  \"\"\"\n",
    "  text = text.replace(\"\\t\", \"\")  # Remove tabs\n",
    "  text = text.replace(\"\\n\", \" \")  # Replace newlines with space\n",
    "  # Add any other replacements if needed\n",
    "  return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1:MID LEVEL INTERROGATE\n",
    "import os\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "directory_path = \"./json_output/numbers\"\n",
    "\n",
    "def gpt_call(sys_prompt, user_input, model):\n",
    "    gpt_knowledge_answer = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-16k\",\n",
    "    messages=[{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": sys_prompt\n",
    "    }, {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_input\n",
    "    }],\n",
    "    temperature=0.8,\n",
    "    )[\"choices\"][0][\"message\"]['content']\n",
    "    return gpt_knowledge_answer\n",
    "\n",
    "\n",
    "if not os.path.exists(directory_path):\n",
    "    print(f\"Directory {directory_path} does not exist.\")\n",
    "else:\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            if 'test' in filename:\n",
    "                continue\n",
    "            \n",
    "            filename = data['filename']\n",
    "            package = data['package']\n",
    "            functions = data['functions']\n",
    "            types = data['types']\n",
    "            structs = data['structs']\n",
    "            interfaces = data['interfaces']\n",
    "            variables = data['variables']\n",
    "            constants = data['constants']\n",
    "            function_calls = data['function_calls']\n",
    "            code_content = data['code_content']\n",
    "\n",
    "            user_input_dict = {\n",
    "                \"File\": filename,\n",
    "                \"Package\": package,\n",
    "                \"Functions\": [function['name'] for function in functions] if functions else None,\n",
    "                \"Types\": [type_['name'] for type_ in types] if types else None,\n",
    "                \"Structs\": [struct['name'] for struct in structs] if structs else None,\n",
    "                \"Interfaces\": [interface['name'] for interface in interfaces] if interfaces else None,\n",
    "                \"Code\": code_content,\n",
    "            }\n",
    "            user_input_dict = {key: value for key, value in user_input_dict.items() if value is not None}\n",
    "\n",
    "            user_input = json.dumps(user_input_dict)\n",
    "\n",
    "            sys_prompt_qa = \"\"\"You are code Q&A bot. Your job is to first analyze a golang backend code base of Acme Inc., cap table management software company.\n",
    "            Secondly, you must produce a list questions and anwsers to them that a senior software engineer in Acme Inc. can ask and answer about the code. \n",
    "            #SAMPLE INPUT# {\"File\": \"filename.go\", \"Package\": \"some_package\", \"Code\": \"golang code\"}\n",
    "            Optional fields are \"Functions\", \"Types\", \"Structs\", \"Methods\", \"Interfaces\". They contain names of the elements, not the full code.\n",
    "            You need them to create complete Q&A in case full code is not provided due to input size limit.\n",
    "            #QUESTION CONTEXT# Always ask specific questions about the file, ask questions about the file in the context of its package. Ask and asnwer \n",
    "            questions as if you are senior SWE. Do not ask about what packages are imported to the file. Don't ask about arguements or returns of the function. \n",
    "            You must produce anywhere from 10 to 25 questions and answers depending on the code lenght.\n",
    "            #SAMPLE OUTPUT# Q: What external functions does DetailedExport rely on for its computations? A: The function relies on GetCompanyData\n",
    "            to fetch company...\n",
    "            \"\"\"\n",
    "            sys_prompt_summary = \"\"\"You are code description writer for a golang backend of Acme Inc., a cap table management software company.\n",
    "            Your job is to analyze golang code file and produce a description (max 200 words) of the file, as written by a \n",
    "            senior software engineer in the company. \n",
    "            #SAMPLE INPUT# {\"File\": \"filename.go\", \"Package\": \"some_package\", \"Code\": \"golang code\"}\n",
    "            Optional fields are \"Functions\", \"Types\", \"Structs\", \"Methods\", \"Interfaces\". They contain names of the elements, not the full code.\n",
    "            #SUMMARY CONTEXT# You must describe what is the intent of the code. What is the code doing? What is the code used for?\n",
    "            Always mention specific names of code elements in your description.\"\"\"\n",
    "      \n",
    "            with ThreadPoolExecutor() as executor:\n",
    "                future_qa = executor.submit(gpt_call, sys_prompt_qa, trim_input(user_input), \"gpt-3.5-turbo-16k\")\n",
    "                future_summary = executor.submit(gpt_call, sys_prompt_summary, trim_input(user_input), \"gpt-3.5-turbo-16k\")\n",
    "                \n",
    "                qa = future_qa.result()\n",
    "                summary = future_summary.result()\n",
    "\n",
    "            data[\"qa\"] = qa\n",
    "            data[\"summary\"] = summary\n",
    "\n",
    "            with open(file_path, \"w\") as file:\n",
    "                json.dump(data, file, indent=4)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: HIGH LEVEL INTERROGATE\n",
    "import os\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "directory_path = \"./json_output/numbers\"\n",
    "PACKAGE = \"calcs\"\n",
    "\n",
    "def gpt_call_high(sys_prompt, user_input, model):\n",
    "    gpt_knowledge_answer = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4-32k\",\n",
    "    messages=[{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": sys_prompt\n",
    "    }, {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_input\n",
    "    }],\n",
    "    )[\"choices\"][0][\"message\"]['content']\n",
    "    return gpt_knowledge_answer\n",
    "\n",
    "package_descriptions = {\n",
    "    \"usecases\": \"Business and Workflow logic\",\n",
    "}\n",
    "\n",
    "user_input_high = \"\"\n",
    "\n",
    "if not os.path.exists(directory_path):\n",
    "    print(f\"Directory {directory_path} does not exist.\")\n",
    "else:\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "            \n",
    "            filename = data['filename']\n",
    "            functions = data['functions']\n",
    "            types = data['types']\n",
    "            structs = data['structs']\n",
    "            methods = data['methods']\n",
    "            interfaces = data['interfaces']\n",
    "            variables = data['variables']\n",
    "            constants = data['constants']\n",
    "            summary =   data['summary']\n",
    "            imports = data['imports']\n",
    "            package = data['package']\n",
    "            import_packages = data['import_packages']\n",
    "\n",
    "            Internal_imported_packages = \"\"\n",
    "            if import_packages:\n",
    "                for pck in import_packages:\n",
    "                    if pck in package_descriptions:\n",
    "                        Internal_imported_packages += f\"{pck} ({package_descriptions[pck]}), \"\n",
    "                    else:\n",
    "                        Internal_imported_packages += f\"{pck}, \"\n",
    "            \n",
    "\n",
    "            user_input_dict = {\n",
    "                \"File\": filename,\n",
    "                \"Functions\": [function['name'] for function in functions] if functions else None,\n",
    "                \"Types\": [type_['name'] for type_ in types] if types else None,\n",
    "                \"Structs\": [struct['name'] for struct in structs] if structs else None,\n",
    "                \"Methods\": [method['name'] for method in methods] if methods else None,\n",
    "                \"Interfaces\": [interface['name'] for interface in interfaces] if interfaces else None,\n",
    "                'Internal Imported Packages': Internal_imported_packages if Internal_imported_packages else None,\n",
    "                'External Imported Packages': str(imports) if imports else None,\n",
    "                \"Description\": summary\n",
    "            }\n",
    "            user_input_dict = {key: value for key, value in user_input_dict.items() if value is not None}\n",
    "            user_input_high += json.dumps(user_input_dict)\n",
    "\n",
    "\n",
    "high_level_sys_prompt_qa = f\"\"\"You are code Q&A bot. Your job is to first analyze a golang package \"{package}\" from backend code base of Acme Inc., cap table management software company.\n",
    "You must produce a list questions and anwsers to them that a senior software engineer in Acme Inc. can ask and answer about this package. \n",
    "You are given a \"Filename\" and \"Description\" of each file in this package.\n",
    "Optional fields are \"Functions\", \"Types\", \"Structs\", \"Methods\", \"Interfaces\". They contain names of the elements, you might use to create questions.\n",
    "#QUESTION CONTEXT# Always ask specific questions about the package, ask about the intent of this package, what is it used for, what is it doing?\n",
    "You must produce anywhere from 25-30 questions and answers depending on the size of the package.\n",
    "#SAMPLE OUTPUT# Q: What external functions does DetailedExport in numbers package rely on for its computations? A: The function relies on GetCompanyData\n",
    "to fetch company...\n",
    "\"\"\"\n",
    "high_level_sys_prompt_summary = f\"\"\"You are code description writer for a golang package {package} from backend of Acme Inc., a cap table management software company.\n",
    "Your job is to analyze the {package} package and produce a description of it (400 words), as written by a senior software engineer in the company. \n",
    "You are given a \"Filename\" and \"Description\" of each file in this package.\n",
    "Optional fields are \"Functions\", \"Types\", \"Structs\", \"Methods\", \"Interfaces\". They contain names of the elements, you might use to create questions.\n",
    "#SUMMARY CONTEXT# You must describe what is the intent of the package. What this package is doing? What is it used for?\n",
    "Always mention specific names of code elements in your description.\"\"\"\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future_qa = executor.submit(gpt_call_high, high_level_sys_prompt_qa, user_input_high, \"gpt-4-32k\")\n",
    "    future_summary = executor.submit(gpt_call_high, high_level_sys_prompt_summary, user_input_high, \"gpt-4-32k\")\n",
    "    \n",
    "    qa_high = future_qa.result()\n",
    "    summary_high = future_summary.result()\n",
    "\n",
    "data_high = {}\n",
    "\n",
    "data_high[\"qa\"] = qa_high\n",
    "data_high[\"summary\"] = summary_high\n",
    "\n",
    "with open(f\"{PACKAGE}.json\", \"w\") as file:\n",
    "    json.dump(data_high, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOW LEVEL INTERROG PARALLELIZED\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from multiprocessing import Manager\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from json import JSONDecodeError\n",
    "# Create a shared Manager object\n",
    "import json\n",
    "import os\n",
    "manager = Manager()\n",
    "\n",
    "directory_path = \"\"\n",
    "\n",
    "# Create a shared variable for the rate limit flag\n",
    "rate_limit_hit = manager.Value(bool, False)\n",
    "\n",
    "with open(\"functions.json\", \"r\") as f:\n",
    "    functions_list = json.load(f)\n",
    "\n",
    "def gpt_call_low(user_input, type, filename, package, model):\n",
    "\n",
    "    sys_prompt_low_level = f\"\"\"#INSTRUCTION# You are a code Q&A bot. Your job is to first analyze a {type}, from the {filename} file \n",
    "    from the numbers package in golang code from the codebase of Acme Inc., a cap table management software company. \n",
    "    Numbers package is responsible for bringing data and calcs together to create small chunks of useful numbers for a given entity. \n",
    "    All functions in this package will be related to calculations, hence you all the questions and answers you should ask must be\n",
    "    related to the way the  {type} is used for calculations of different element of the capitalization table.\n",
    "    In most cases you will be given the code of the function to call, as well as the code of all \n",
    "    function calls made in the function, use this context to produce questions and answers.\n",
    "    #QUESTION CONTEXT# Always ask specific questions about the {type}, and in the context of its file. Formulate \n",
    "    questions and answers as if you are a senior SWE. Don't ask trivial questions to explain the names of the input, return of any trivial\n",
    "    questions about the structure of the code. You must focus on the intent of the code. What this function is useful for in numbers package?\n",
    "    What this function calculates. How is it used in the cap table etc. You must produce up to 10 questions and answers, depending on the code length.\n",
    "    #SAMPLE OUTPUT FORM# Q: How fuly diluted shares are calculated in the CalculateShares function? A: The function calculates(continued..)\"\"\"\n",
    "\n",
    "    if model == \"gpt-4\":\n",
    "        system_msg = sys_prompt_low_level\n",
    "        user_msg = user_input\n",
    "    else:\n",
    "        system_msg = \"You are bot that produces questions and answers about code by ananlyzing code of th function and code of the functions called by this function.\"\n",
    "        user_msg = user_input\n",
    "\n",
    "\n",
    "    if rate_limit_hit.value:\n",
    "        print(\"Rate limit hit, sleeping for 60 seconds\")\n",
    "        time.sleep(60)\n",
    "        rate_limit_hit.value = False\n",
    "\n",
    "    msgs=[{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_msg\n",
    "    }, {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_msg\n",
    "    }]\n",
    "\n",
    "    print(filename, model)\n",
    "    print(msgs)\n",
    "    print('-----------')\n",
    "\n",
    "    while True:  # Keep trying until we get a valid response\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages=msgs,\n",
    "                max_tokens=1100,\n",
    "                temperature=0.8\n",
    "            )\n",
    "\n",
    "            response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "            prompt_tokens, completion_tokens = response['usage']['prompt_tokens'], response['usage']['completion_tokens']\n",
    "            print(f\"{response_message[:200]}\\n\")\n",
    "            print(\"------------------\")\n",
    "            return response_message  # Return the response if it's valid\n",
    "\n",
    "        except JSONDecodeError as e:\n",
    "            print(f'JSONDecodeError occurred: {e}')\n",
    "            time.sleep(10)\n",
    "            continue \n",
    "        except openai.error.ServiceUnavailableError as e:\n",
    "            print(f'Server error: {e}. Retrying in 10 seconds.')\n",
    "            time.sleep(10)  \n",
    "            continue\n",
    "        except openai.error.RateLimitError as e: \n",
    "            print(f'Hit rate limit. Waiting 60 sec')\n",
    "            rate_limit_hit.value = True\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "        except openai.error.APIError as e: \n",
    "            print(f'BAD GATEWAY ERROR. Waiting 20 sec')\n",
    "            rate_limit_hit.value = True\n",
    "            time.sleep(20)  \n",
    "            continue\n",
    "\n",
    "def worker(input_data):\n",
    "    # Unpack the input data\n",
    "    user_input, code_type, filename, package, model = input_data\n",
    "    return gpt_call_low(trim_input(user_input), code_type, filename, package, model)\n",
    "\n",
    "# Create a ThreadPoolExecutor\n",
    "executor = ThreadPoolExecutor(max_workers=8)  # Adjust the number of workers as needed\n",
    "\n",
    "if not os.path.exists(directory_path):\n",
    "    print(f\"Directory {directory_path} does not exist.\")\n",
    "else:\n",
    "    # for each file\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "            # Prepare the tasks for the executor\n",
    "            tasks = []\n",
    "            print(filename)\n",
    "            if data['functions']:\n",
    "                for item in data['functions']:\n",
    "                    \n",
    "                    user_input = f\" #Function to produce Q&A about#: {clean_text(item['body'])}\\n\"\n",
    "                    try:\n",
    "                        user_input += \"#Code of the functions called by this function. Use this code context to produce better Q&A#:\\n\"\n",
    "                        function_injected = 0\n",
    "                        if item['functions_called']:\n",
    "                            for function in item['functions_called']:\n",
    "                                name = function['name']\n",
    "                                if name in functions_list:\n",
    "                                    function_injected +=1\n",
    "                                    user_input += f\"\\n #Function name {name}#: #Code#: {clean_text(functions_list[name])}\\n\"\n",
    "\n",
    "                        print(f\"Injected {function_injected} functions\")\n",
    "                    except KeyError:\n",
    "                        print(filename, \"no functions called\")\n",
    "\n",
    "                    if get_tokens(user_input)+300 > 8000:\n",
    "                        model = \"gpt-3.5-turbo-16k\"\n",
    "                    elif get_tokens(user_input)+300 > 15500:\n",
    "                        user_input = user_input[:25000]\n",
    "                    else: \n",
    "                        model = \"gpt-4\"\n",
    "\n",
    "                    tasks.append((user_input, 'function', filename, data['package'], model))\n",
    "\n",
    "\n",
    "            for key in ['types', 'structs', 'interfaces']:\n",
    "                if data[key]:\n",
    "                    for item in data[key]:\n",
    "                        user_input = f\"{key.capitalize()[:-1]} name: {item['name']} | Code: {item['body']}\\n\"\n",
    "                        if get_tokens(user_input)+300 > 8000:\n",
    "                            model = \"gpt-3.5-turbo-16k\"\n",
    "                        elif get_tokens(user_input)+300 > 15500:\n",
    "                            user_input = user_input[:25000]\n",
    "                            model = \"gpt-3.5-turbo-16k\"\n",
    "                        else: \n",
    "                            model = \"gpt-4\"\n",
    "                        tasks.append((user_input, key[:-1], filename, data['package'], model))\n",
    "\n",
    "            # Run the tasks using the executor\n",
    "            results = list(executor.map(worker, tasks))\n",
    "\n",
    "            # Assign the results back to the original data\n",
    "            idx = 0\n",
    "            for key in ['functions', 'types', 'structs', 'interfaces']:\n",
    "                if data[key]:\n",
    "                    for item in data[key]:\n",
    "                        item['qa'] = results[idx]\n",
    "                        print(item['qa'])\n",
    "                        idx += 1\n",
    "\n",
    "            with open(file_path, \"w\") as file:\n",
    "                json.dump(data, file, indent=4)\n",
    "            print(filename, \"done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
